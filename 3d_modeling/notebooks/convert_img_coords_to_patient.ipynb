{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-25T02:44:56.031065Z",
     "start_time": "2024-09-25T02:44:36.581076Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pydicom import dcmread\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, '../../data/SpineNet')\n",
    "import spinenet\n",
    "from spinenet import SpineNet, download_example_scan\n",
    "from spinenet.io import load_dicoms_from_folder\n",
    "\n",
    "spnt = SpineNet(device='cuda:0', verbose=True)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Victor\\.conda\\envs\\python-doodles\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Victor\\.conda\\envs\\python-doodles\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Detection Model...\n",
      "==> Loading model trained for 436 epochs...\n",
      "Loading Appearance Model...\n",
      "==> Loading model trained for 188 epochs...\n",
      "Loading Context Model...\n",
      "==> Loading model trained for 17 epochs...\n",
      "Loading Grading Model...\n",
      "==> Loading model trained for 2 epochs...\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T02:44:56.036460Z",
     "start_time": "2024-09-25T02:44:56.032070Z"
    }
   },
   "cell_type": "code",
   "source": [
    "LEVELS = [\"L1\", \"L2\", \"L3\", \"L4\", \"L5\", \"S1\"]\n",
    "COLORS = {\n",
    "    \"L1\": \"red\",\n",
    "    \"L2\": \"blue\",\n",
    "    \"L3\": \"green\",\n",
    "    \"L4\": \"yellow\",\n",
    "    \"L5\": \"white\",\n",
    "    \"S1\": \"purple\"\n",
    "}"
   ],
   "id": "bc4d7c199292c023",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T02:44:56.071317Z",
     "start_time": "2024-09-25T02:44:56.037489Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_descs_path = \"../../data/rsna-2024-lumbar-spine-degenerative-classification/train_series_descriptions.csv\"\n",
    "train_images_path = \"../../data/rsna-2024-lumbar-spine-degenerative-classification/train_images\""
   ],
   "id": "e1edbbde9d31b2e7",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T02:44:56.096465Z",
     "start_time": "2024-09-25T02:44:56.072828Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_descs = pd.read_csv(train_descs_path)\n",
    "train_descs = train_descs[train_descs[\"series_description\"] == \"Sagittal T1\"]\n",
    "train_descs"
   ],
   "id": "c519efa461b9a378",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        study_id   series_id series_description\n",
       "1        4003253  1054713880        Sagittal T1\n",
       "4        4646740  3486248476        Sagittal T1\n",
       "8        7143189  3219733239        Sagittal T1\n",
       "10       8785691  1570286759        Sagittal T1\n",
       "14      10728036  2399638375        Sagittal T1\n",
       "...          ...         ...                ...\n",
       "6281  4282019580  3029774733        Sagittal T1\n",
       "6283  4283570761  2708429184        Sagittal T1\n",
       "6285  4284048608  1875151370        Sagittal T1\n",
       "6288  4287160193   327893304        Sagittal T1\n",
       "6293  4290709089  4237840455        Sagittal T1\n",
       "\n",
       "[1980 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>series_id</th>\n",
       "      <th>series_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4003253</td>\n",
       "      <td>1054713880</td>\n",
       "      <td>Sagittal T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4646740</td>\n",
       "      <td>3486248476</td>\n",
       "      <td>Sagittal T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7143189</td>\n",
       "      <td>3219733239</td>\n",
       "      <td>Sagittal T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8785691</td>\n",
       "      <td>1570286759</td>\n",
       "      <td>Sagittal T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10728036</td>\n",
       "      <td>2399638375</td>\n",
       "      <td>Sagittal T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6281</th>\n",
       "      <td>4282019580</td>\n",
       "      <td>3029774733</td>\n",
       "      <td>Sagittal T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6283</th>\n",
       "      <td>4283570761</td>\n",
       "      <td>2708429184</td>\n",
       "      <td>Sagittal T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6285</th>\n",
       "      <td>4284048608</td>\n",
       "      <td>1875151370</td>\n",
       "      <td>Sagittal T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6288</th>\n",
       "      <td>4287160193</td>\n",
       "      <td>327893304</td>\n",
       "      <td>Sagittal T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6293</th>\n",
       "      <td>4290709089</td>\n",
       "      <td>4237840455</td>\n",
       "      <td>Sagittal T1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1980 rows × 3 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T02:44:56.105276Z",
     "start_time": "2024-09-25T02:44:56.099204Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_centers(data):\n",
    "    centers = {}\n",
    "    for item in data:\n",
    "        level = item[\"predicted_label\"]\n",
    "        if level in LEVELS:\n",
    "            average_polygon = item[\"average_polygon\"]\n",
    "            centroid_x = np.mean(average_polygon[:, 0])\n",
    "            centroid_y = np.mean(average_polygon[:, 1])\n",
    "            centroid_z = item[\"slice_nos\"][len(item[\"slice_nos\"])//2]\n",
    "            centers[level] = (centroid_x, centroid_y, centroid_z)\n",
    "    return centers"
   ],
   "id": "e2b3e1a41508752f",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T02:44:56.111850Z",
     "start_time": "2024-09-25T02:44:56.107406Z"
    }
   },
   "cell_type": "code",
   "source": [
    "centers_per_study = {\n",
    "    \"study_id\": [],\n",
    "    \"series_id\": [],\n",
    "    \"x\": [],\n",
    "    \"y\": [],\n",
    "    \"instance_number\": [],\n",
    "    \"level\": []\n",
    "}\n"
   ],
   "id": "b0efe7bba8ec7be5",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T02:46:12.088883Z",
     "start_time": "2024-09-25T02:44:56.113855Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for index, row in tqdm(train_descs.iterrows()):\n",
    "    scan = load_dicoms_from_folder(f\"{train_images_path}/{row['study_id']}/{row['series_id']}\", require_extensions=False)\n",
    "    num_slices = scan.volume.shape[-1]\n",
    "\n",
    "    vert_dicts = spnt.detect_vb(scan.volume, scan.pixel_spacing)\n",
    "    centers = calculate_centers(vert_dicts)\n",
    "    \n",
    "    for level in centers:\n",
    "        centers_per_study[\"study_id\"].append(row['study_id'])\n",
    "        centers_per_study[\"series_id\"].append(row['series_id'])\n",
    "        centers_per_study[\"level\"].append(level)\n",
    "        \n",
    "        centers_per_study[\"x\"].append(centers[level][0])\n",
    "        centers_per_study[\"y\"].append(centers[level][1])\n",
    "        centers_per_study[\"instance_number\"].append(centers[level][2])\n"
   ],
   "id": "d60daf4b3a9b230",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [01:14, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 7\u001B[0m\n\u001B[0;32m      4\u001B[0m scan \u001B[38;5;241m=\u001B[39m load_dicoms_from_folder(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrain_images_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrow[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstudy_id\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrow[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mseries_id\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, require_extensions\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m      5\u001B[0m num_slices \u001B[38;5;241m=\u001B[39m scan\u001B[38;5;241m.\u001B[39mvolume\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m----> 7\u001B[0m vert_dicts \u001B[38;5;241m=\u001B[39m spnt\u001B[38;5;241m.\u001B[39mdetect_vb(scan\u001B[38;5;241m.\u001B[39mvolume, scan\u001B[38;5;241m.\u001B[39mpixel_spacing)\n\u001B[0;32m      8\u001B[0m centers \u001B[38;5;241m=\u001B[39m calculate_centers(vert_dicts)\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m level \u001B[38;5;129;01min\u001B[39;00m centers:\n",
      "File \u001B[1;32mD:\\Users\\Victor\\Documents\\python-doodles\\rsna-2024\\notebooks\\../../data/SpineNet\\spinenet\\main.py:147\u001B[0m, in \u001B[0;36mSpineNet.detect_vb\u001B[1;34m(self, volume, pixel_spacing, debug, penalise_skips, remove_single_slice_detections)\u001B[0m\n\u001B[0;32m    124\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    125\u001B[0m \u001B[38;5;124;03mUse SpineNet to detect and label vertebral bodies in a volume.\u001B[39;00m\n\u001B[0;32m    126\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    143\u001B[0m \u001B[38;5;124;03m    A list of dictionaries containing the vertebrae labels, their corresponding polygons and the slices in which they appear.\u001B[39;00m\n\u001B[0;32m    144\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    146\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m volume\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m3\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mscan should be a 3-dimensional array of shape HxWxS.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m--> 147\u001B[0m detect_ans \u001B[38;5;241m=\u001B[39m detect_and_group(\n\u001B[0;32m    148\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdetection_model,\n\u001B[0;32m    149\u001B[0m     volume,\n\u001B[0;32m    150\u001B[0m     remove_excess_black_space\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mremove_black_space,\n\u001B[0;32m    151\u001B[0m     plot_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    152\u001B[0m     using_resnet\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m    153\u001B[0m     corner_threshold\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcorner_threshold,\n\u001B[0;32m    154\u001B[0m     centroid_threshold\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcentroid_threshold,\n\u001B[0;32m    155\u001B[0m     group_across_slices_threshold\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroup_across_slices_threshold,\n\u001B[0;32m    156\u001B[0m     remove_single_slice_detections\u001B[38;5;241m=\u001B[39mremove_single_slice_detections,\n\u001B[0;32m    157\u001B[0m     pixel_spacing\u001B[38;5;241m=\u001B[39mpixel_spacing,\n\u001B[0;32m    158\u001B[0m     device\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice,\n\u001B[0;32m    159\u001B[0m     debug\u001B[38;5;241m=\u001B[39mdebug,\n\u001B[0;32m    160\u001B[0m )\n\u001B[0;32m    161\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m debug:\n\u001B[0;32m    162\u001B[0m     vert_dicts, patches, patches_dicts, detection_dicts, transform_info_dicts \u001B[38;5;241m=\u001B[39m detect_ans\n",
      "File \u001B[1;32mD:\\Users\\Victor\\Documents\\python-doodles\\rsna-2024\\notebooks\\../../data/SpineNet\\spinenet\\utils\\detect_and_group.py:69\u001B[0m, in \u001B[0;36mdetect_and_group\u001B[1;34m(detection_net, scan, remove_excess_black_space, pixel_spacing, plot_outputs, using_resnet, corner_threshold, centroid_threshold, group_across_slices_threshold, remove_single_slice_detections, device, debug)\u001B[0m\n\u001B[0;32m     65\u001B[0m patches, transform_info_dicts \u001B[38;5;241m=\u001B[39m split_into_patches_exhaustive(\n\u001B[0;32m     66\u001B[0m     scan, pixel_spacing\u001B[38;5;241m=\u001B[39mpixel_spacing, overlap_param\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.4\u001B[39m, using_resnet\u001B[38;5;241m=\u001B[39musing_resnet\n\u001B[0;32m     67\u001B[0m )\n\u001B[0;32m     68\u001B[0m \u001B[38;5;66;03m# group the detections made in each patch into slice level detections\u001B[39;00m\n\u001B[1;32m---> 69\u001B[0m detection_dicts, patches_dicts \u001B[38;5;241m=\u001B[39m make_in_slice_detections(\n\u001B[0;32m     70\u001B[0m     detection_net,\n\u001B[0;32m     71\u001B[0m     patches,\n\u001B[0;32m     72\u001B[0m     transform_info_dicts,\n\u001B[0;32m     73\u001B[0m     scan\u001B[38;5;241m.\u001B[39mshape,\n\u001B[0;32m     74\u001B[0m     corner_threshold,\n\u001B[0;32m     75\u001B[0m     centroid_threshold,\n\u001B[0;32m     76\u001B[0m     device\u001B[38;5;241m=\u001B[39mdevice,\n\u001B[0;32m     77\u001B[0m )\n\u001B[0;32m     79\u001B[0m vert_dicts \u001B[38;5;241m=\u001B[39m group_slice_detections(\n\u001B[0;32m     80\u001B[0m     detection_dicts,\n\u001B[0;32m     81\u001B[0m     iou_threshold\u001B[38;5;241m=\u001B[39mgroup_across_slices_threshold,\n\u001B[0;32m     82\u001B[0m     remove_single_slice_detections\u001B[38;5;241m=\u001B[39mremove_single_slice_detections,\n\u001B[0;32m     83\u001B[0m )\n\u001B[0;32m     85\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m debug:\n",
      "File \u001B[1;32mD:\\Users\\Victor\\Documents\\python-doodles\\rsna-2024\\notebooks\\../../data/SpineNet\\spinenet\\utils\\detection_post_processing.py:52\u001B[0m, in \u001B[0;36mmake_in_slice_detections\u001B[1;34m(detection_net, patches, transform_info_dicts, scan_shape, corner_threshold, centroid_threshold, device)\u001B[0m\n\u001B[0;32m     49\u001B[0m net_input \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat([patches_tensor, flipped_patches_tensor], axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m     50\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m     51\u001B[0m     \u001B[38;5;66;03m# both_net_output = detection_net(net_input.to(device).float()).cpu()\u001B[39;00m\n\u001B[1;32m---> 52\u001B[0m     net_output \u001B[38;5;241m=\u001B[39m detection_net(patches_tensor\u001B[38;5;241m.\u001B[39mto(device)\u001B[38;5;241m.\u001B[39mfloat())\u001B[38;5;241m.\u001B[39mcpu()\n\u001B[0;32m     54\u001B[0m patches_dicts\u001B[38;5;241m.\u001B[39mappend({\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpatches\u001B[39m\u001B[38;5;124m\"\u001B[39m: patches_tensor\u001B[38;5;241m.\u001B[39mnumpy(), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnet_output\u001B[39m\u001B[38;5;124m\"\u001B[39m: net_output\u001B[38;5;241m.\u001B[39mnumpy(), \n\u001B[0;32m     55\u001B[0m                       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlandmark_points\u001B[39m\u001B[38;5;124m\"\u001B[39m: {}, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlandmark_arrows\u001B[39m\u001B[38;5;124m\"\u001B[39m: {}})\n\u001B[0;32m     57\u001B[0m all_corners \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpoints\u001B[39m\u001B[38;5;124m\"\u001B[39m: {}, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marrows\u001B[39m\u001B[38;5;124m\"\u001B[39m: {}}\n",
      "File \u001B[1;32m~\\.conda\\envs\\python-doodles\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\.conda\\envs\\python-doodles\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Users\\Victor\\Documents\\python-doodles\\rsna-2024\\notebooks\\../../data/SpineNet\\spinenet\\models\\vfr.py:170\u001B[0m, in \u001B[0;36mVFRResNetDetector.forward\u001B[1;34m(self, x, with_output_feature_map)\u001B[0m\n\u001B[0;32m    168\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, block \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mup_blocks, \u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m    169\u001B[0m     key \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlayer_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mVFRResNetDetector\u001B[38;5;241m.\u001B[39mDEPTH\u001B[38;5;250m \u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;250m \u001B[39mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m--> 170\u001B[0m     x \u001B[38;5;241m=\u001B[39m block(x, pre_pools[key])\n\u001B[0;32m    171\u001B[0m output_feature_map \u001B[38;5;241m=\u001B[39m x\n\u001B[0;32m    172\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mout(x)\n",
      "File \u001B[1;32m~\\.conda\\envs\\python-doodles\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\.conda\\envs\\python-doodles\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Users\\Victor\\Documents\\python-doodles\\rsna-2024\\notebooks\\../../data/SpineNet\\spinenet\\models\\vfr.py:99\u001B[0m, in \u001B[0;36mUpBlockForUNetWithResNet50.forward\u001B[1;34m(self, up_x, down_x)\u001B[0m\n\u001B[0;32m     92\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, up_x, down_x):\n\u001B[0;32m     93\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     94\u001B[0m \n\u001B[0;32m     95\u001B[0m \u001B[38;5;124;03m    :param up_x: this is the output from the previous up block\u001B[39;00m\n\u001B[0;32m     96\u001B[0m \u001B[38;5;124;03m    :param down_x: this is the output from the down block\u001B[39;00m\n\u001B[0;32m     97\u001B[0m \u001B[38;5;124;03m    :return: upsampled feature map\u001B[39;00m\n\u001B[0;32m     98\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m---> 99\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mupsample(up_x)\n\u001B[0;32m    100\u001B[0m     x \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat([x, down_x], \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m    101\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv_block_1(x)\n",
      "File \u001B[1;32m~\\.conda\\envs\\python-doodles\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\.conda\\envs\\python-doodles\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\python-doodles\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001B[0m, in \u001B[0;36mSequential.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[1;32m--> 217\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m module(\u001B[38;5;28minput\u001B[39m)\n\u001B[0;32m    218\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[1;32m~\\.conda\\envs\\python-doodles\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\.conda\\envs\\python-doodles\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\python-doodles\\Lib\\site-packages\\torch\\nn\\modules\\upsampling.py:157\u001B[0m, in \u001B[0;36mUpsample.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    156\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 157\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39minterpolate(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msize, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscale_factor, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmode, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39malign_corners,\n\u001B[0;32m    158\u001B[0m                          recompute_scale_factor\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrecompute_scale_factor)\n",
      "File \u001B[1;32m~\\.conda\\envs\\python-doodles\\Lib\\site-packages\\torch\\nn\\functional.py:4065\u001B[0m, in \u001B[0;36minterpolate\u001B[1;34m(input, size, scale_factor, mode, align_corners, recompute_scale_factor, antialias)\u001B[0m\n\u001B[0;32m   4059\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mare_deterministic_algorithms_enabled() \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39mis_cuda:\n\u001B[0;32m   4060\u001B[0m             \u001B[38;5;66;03m# Use slow decomp whose backward will be in terms of index_put\u001B[39;00m\n\u001B[0;32m   4061\u001B[0m             \u001B[38;5;66;03m# importlib is required because the import cannot be top level\u001B[39;00m\n\u001B[0;32m   4062\u001B[0m             \u001B[38;5;66;03m# (cycle) and cannot be nested (TS doesn't support)\u001B[39;00m\n\u001B[0;32m   4063\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m importlib\u001B[38;5;241m.\u001B[39mimport_module(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtorch._decomp.decompositions\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39m_upsample_linear_vec(\n\u001B[0;32m   4064\u001B[0m                 \u001B[38;5;28minput\u001B[39m, output_size, align_corners, scale_factors)\n\u001B[1;32m-> 4065\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39m_nn\u001B[38;5;241m.\u001B[39mupsample_bilinear2d(\u001B[38;5;28minput\u001B[39m, output_size, align_corners, scale_factors)\n\u001B[0;32m   4066\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39mdim() \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m5\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrilinear\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m   4067\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m align_corners \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "centers_per_study = pd.DataFrame.from_dict(centers_per_study)\n",
    "centers_per_study"
   ],
   "id": "63c8139871f29d9a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T02:46:12.092397Z",
     "start_time": "2024-09-25T02:46:12.090891Z"
    }
   },
   "cell_type": "code",
   "source": "centers_per_study.to_csv('../../data/SpineNet/centers_per_study.csv', index=False)",
   "id": "9b234263cfe5a72c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def convert_coords_to_patient(x, y, dicom_slice):\n",
    "    \n",
    "    # transform_matrix_factor = np.matrix(\n",
    "    #     [[0, 1, 0, 0],\n",
    "    #      [1, 0, 0, 0],\n",
    "    #      [0, 0, 1, 0],\n",
    "    #      [0, 0, 0, 1]]\n",
    "    # )\n",
    "        \n",
    "    dX, dY = dicom_slice.PixelSpacing\n",
    "    \n",
    "    X = np.array(list(dicom_slice.ImageOrientationPatient[:3]) + [0]) * dY\n",
    "    Y = np.array(list(dicom_slice.ImageOrientationPatient[3:]) + [0]) * dX\n",
    "\n",
    "    S = np.array(list(dicom_slice.ImagePositionPatient) + [1])\n",
    "\n",
    "    transform_matrix = np.array([Y, X, np.zeros(len(X)), S]).T\n",
    "    # transform_matrix = transform_matrix @ transform_matrix_factor\n",
    "\n",
    "    return (transform_matrix @ np.array([y, x, 0, 1]).T)"
   ],
   "id": "e2ab8dd6e58f6b71",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_images_basepath = \"../../data/rsna-2024-lumbar-spine-degenerative-classification/train_images\"\n",
    "\n",
    "patient_coords_dict = {\n",
    "    \"study_id\": [],\n",
    "    \"level\": [],\n",
    "    \"x\": [],\n",
    "    \"y\": [],\n",
    "    \"z\": []\n",
    "}\n",
    "\n",
    "for index, group in centers_per_study.groupby(\"study_id\"):\n",
    "    for row_index, row in group.iterrows():\n",
    "        dicom_slice_path = f\"{train_images_basepath}/{row['study_id']}/{row['series_id']}/{row['instance_number']}.dcm\"\n",
    "        dicom_slice = dcmread(dicom_slice_path)\n",
    "        coords = convert_coords_to_patient(row['x'], row['y'], dicom_slice)\n",
    "        \n",
    "        patient_coords_dict[\"study_id\"].append(row['study_id'])\n",
    "        patient_coords_dict[\"level\"].append(row['level'])\n",
    "        patient_coords_dict[\"x\"].append(coords[0])\n",
    "        patient_coords_dict[\"y\"].append(coords[1])\n",
    "        patient_coords_dict[\"z\"].append(coords[2])\n",
    "    \n",
    "patient_coords = pd.DataFrame.from_dict(patient_coords_dict)\n",
    "patient_coords"
   ],
   "id": "b3782397c5b906a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "patient_coords.to_csv('../../data/SpineNet/coords_3d.csv', index=False)",
   "id": "a39142bfef40f99b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T02:46:52.109051Z",
     "start_time": "2024-09-25T02:46:52.070853Z"
    }
   },
   "cell_type": "code",
   "source": "patient_coords = pd.read_csv('../../data/SpineNet/coords_3d.csv')",
   "id": "e1e89fa8a50992c8",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T02:46:56.796797Z",
     "start_time": "2024-09-25T02:46:52.782269Z"
    }
   },
   "cell_type": "code",
   "source": [
    "patient_bounding_boxes_dict = {\n",
    "    \"study_id\": [],\n",
    "    \"level\": [],\n",
    "    \"x\": [],\n",
    "    \"y\": [],\n",
    "    \"z\": [],\n",
    "    \"x_min\": [],\n",
    "    \"y_min\": [],\n",
    "    \"z_min\": [],\n",
    "    \"x_max\": [],\n",
    "    \"y_max\": [],\n",
    "    \"z_max\": [],\n",
    "}\n",
    "\n",
    "for index, group in patient_coords.groupby(\"study_id\"):\n",
    "    ordered_group = group.sort_values(by=\"level\", ascending=True)\n",
    "    if len(ordered_group) != 6:\n",
    "        continue\n",
    "    for level_index in range(5):\n",
    "        patient_bounding_boxes_dict[\"study_id\"].append(ordered_group['study_id'].iloc[0])\n",
    "        level_label = ordered_group['level'].iloc[level_index].lower() + \"_\" + ordered_group['level'].iloc[level_index + 1] \n",
    "        patient_bounding_boxes_dict[\"level\"].append(level_label)\n",
    "        \n",
    "        # Middle vertebra points\n",
    "        pt_0 = np.array(ordered_group.iloc[level_index][[\"x\", \"y\", \"z\"]])\n",
    "        pt_1 = np.array(ordered_group.iloc[level_index + 1][[\"x\", \"y\", \"z\"]])\n",
    "        \n",
    "        # Distance vector to the next vertebra\n",
    "        d_vec = np.array(pt_0 - pt_1)\n",
    "        d_size = np.linalg.norm(d_vec)\n",
    "        d_unit = d_vec / d_size\n",
    "        \n",
    "        \n",
    "        # Get a pair of orthogonal vectors to find x and y boundary candidates\n",
    "        orth_1 = np.random.randn(3).astype(np.float64)\n",
    "        orth_1 = orth_1 - orth_1.dot(d_unit) * d_unit\n",
    "        orth_1 = orth_1 / np.linalg.norm(orth_1)\n",
    "        \n",
    "        orth_1 = orth_1.astype(np.float64)\n",
    "        d_unit = d_unit.astype(np.float64)\n",
    "        \n",
    "        orth_2 = np.cross(orth_1, d_unit)\n",
    "        orth_2 = orth_2.astype(np.float64)\n",
    "        \n",
    "        orth_1 *= d_size\n",
    "        orth_2 *= d_size\n",
    "        \n",
    "        # Get candidate points (10 of them, 2 per orthogonal per each vertebra center, and the centers themselves)\n",
    "        c_pts = np.array([pt - vec for pt in (pt_0, pt_1) for vec in (orth_1, orth_2)] + \n",
    "                         [pt + vec for pt in (pt_0, pt_1) for vec in (orth_1, orth_2)] +\n",
    "                         [pt_0, pt_1])\n",
    "        \n",
    "        # x_min and x_max are just the min and max from all this\n",
    "        x_min = np.min(c_pts[:, 0])\n",
    "        x_max = np.max(c_pts[:, 0])\n",
    "        \n",
    "        x_delta = x_max - x_min\n",
    "        x_min -= x_delta * 0.25\n",
    "        x_max += x_delta * 0.25\n",
    "        \n",
    "        # y_max is going to be over the center ys\n",
    "        # And we're going to get y_min by getting y_min over c_pts and then extending the y_min over center ys\n",
    "        c_pts_y_min = np.min(c_pts[:, 1])\n",
    "        c_pts_y_max = np.max(c_pts[:, 1])\n",
    "\n",
    "        y_max = max(pt_0[1], pt_1[1])\n",
    "        y_min = min(pt_0[1], pt_1[1])\n",
    "        \n",
    "        y_max += abs(c_pts_y_max - y_max) * 2\n",
    "        y_min -= abs(c_pts_y_min - y_min) / 2\n",
    "        \n",
    "        # z_max and z_min will be the same as x_min and x_max\n",
    "        z_min = np.min(c_pts[:, 2])\n",
    "        z_max = np.max(c_pts[:, 2])    \n",
    "        \n",
    "        patient_bounding_boxes_dict[\"x_min\"].append(x_min)\n",
    "        patient_bounding_boxes_dict[\"y_min\"].append(y_min)\n",
    "        patient_bounding_boxes_dict[\"z_min\"].append(z_min)\n",
    "        patient_bounding_boxes_dict[\"x_max\"].append(x_max)\n",
    "        patient_bounding_boxes_dict[\"y_max\"].append(y_max)\n",
    "        patient_bounding_boxes_dict[\"z_max\"].append(z_max)\n",
    "\n",
    "patient_bounding_boxes = pd.DataFrame.from_dict(patient_bounding_boxes_dict)\n",
    "patient_bounding_boxes"
   ],
   "id": "572df26a1fc07fc0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        study_id  level      x_min      y_min       z_min      x_max  \\\n",
       "0        4003253  l1_L2 -36.655847  42.989936 -407.043291  41.265211   \n",
       "1        4003253  l2_L3 -46.679861  37.354543 -443.217653  51.760569   \n",
       "2        4003253  l3_L4 -48.780756  36.543628 -476.367429  54.344737   \n",
       "3        4003253  l4_L5 -40.328740  43.086592 -515.936557  41.531377   \n",
       "4        4003253  l5_S1 -51.668266  50.410208 -552.682903  48.441314   \n",
       "...          ...    ...        ...        ...         ...        ...   \n",
       "9670  4290709089  l1_L2 -43.510393  33.467397 -367.854191  46.353134   \n",
       "9671  4290709089  l2_L3 -38.159354  27.699542 -400.269960  39.751942   \n",
       "9672  4290709089  l3_L4 -52.970069  22.280071 -430.541096  53.236578   \n",
       "9673  4290709089  l4_L5 -48.919387  24.208815 -471.329075  47.787466   \n",
       "9674  4290709089  l5_S1 -50.511447  33.302578 -512.741145  47.973782   \n",
       "\n",
       "           y_max       z_max  \n",
       "0     109.074182 -372.836355  \n",
       "1     121.146895 -403.801656  \n",
       "2     123.235800 -439.946070  \n",
       "3     110.674292 -465.232633  \n",
       "4     137.887477 -486.674660  \n",
       "...          ...         ...  \n",
       "9670  115.212463 -316.482825  \n",
       "9671   98.075283 -353.648134  \n",
       "9672  110.434363 -393.918568  \n",
       "9673  109.182820 -423.289584  \n",
       "9674  120.338796 -446.612606  \n",
       "\n",
       "[9675 rows x 8 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>level</th>\n",
       "      <th>x_min</th>\n",
       "      <th>y_min</th>\n",
       "      <th>z_min</th>\n",
       "      <th>x_max</th>\n",
       "      <th>y_max</th>\n",
       "      <th>z_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4003253</td>\n",
       "      <td>l1_L2</td>\n",
       "      <td>-36.655847</td>\n",
       "      <td>42.989936</td>\n",
       "      <td>-407.043291</td>\n",
       "      <td>41.265211</td>\n",
       "      <td>109.074182</td>\n",
       "      <td>-372.836355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4003253</td>\n",
       "      <td>l2_L3</td>\n",
       "      <td>-46.679861</td>\n",
       "      <td>37.354543</td>\n",
       "      <td>-443.217653</td>\n",
       "      <td>51.760569</td>\n",
       "      <td>121.146895</td>\n",
       "      <td>-403.801656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4003253</td>\n",
       "      <td>l3_L4</td>\n",
       "      <td>-48.780756</td>\n",
       "      <td>36.543628</td>\n",
       "      <td>-476.367429</td>\n",
       "      <td>54.344737</td>\n",
       "      <td>123.235800</td>\n",
       "      <td>-439.946070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4003253</td>\n",
       "      <td>l4_L5</td>\n",
       "      <td>-40.328740</td>\n",
       "      <td>43.086592</td>\n",
       "      <td>-515.936557</td>\n",
       "      <td>41.531377</td>\n",
       "      <td>110.674292</td>\n",
       "      <td>-465.232633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4003253</td>\n",
       "      <td>l5_S1</td>\n",
       "      <td>-51.668266</td>\n",
       "      <td>50.410208</td>\n",
       "      <td>-552.682903</td>\n",
       "      <td>48.441314</td>\n",
       "      <td>137.887477</td>\n",
       "      <td>-486.674660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9670</th>\n",
       "      <td>4290709089</td>\n",
       "      <td>l1_L2</td>\n",
       "      <td>-43.510393</td>\n",
       "      <td>33.467397</td>\n",
       "      <td>-367.854191</td>\n",
       "      <td>46.353134</td>\n",
       "      <td>115.212463</td>\n",
       "      <td>-316.482825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9671</th>\n",
       "      <td>4290709089</td>\n",
       "      <td>l2_L3</td>\n",
       "      <td>-38.159354</td>\n",
       "      <td>27.699542</td>\n",
       "      <td>-400.269960</td>\n",
       "      <td>39.751942</td>\n",
       "      <td>98.075283</td>\n",
       "      <td>-353.648134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9672</th>\n",
       "      <td>4290709089</td>\n",
       "      <td>l3_L4</td>\n",
       "      <td>-52.970069</td>\n",
       "      <td>22.280071</td>\n",
       "      <td>-430.541096</td>\n",
       "      <td>53.236578</td>\n",
       "      <td>110.434363</td>\n",
       "      <td>-393.918568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9673</th>\n",
       "      <td>4290709089</td>\n",
       "      <td>l4_L5</td>\n",
       "      <td>-48.919387</td>\n",
       "      <td>24.208815</td>\n",
       "      <td>-471.329075</td>\n",
       "      <td>47.787466</td>\n",
       "      <td>109.182820</td>\n",
       "      <td>-423.289584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9674</th>\n",
       "      <td>4290709089</td>\n",
       "      <td>l5_S1</td>\n",
       "      <td>-50.511447</td>\n",
       "      <td>33.302578</td>\n",
       "      <td>-512.741145</td>\n",
       "      <td>47.973782</td>\n",
       "      <td>120.338796</td>\n",
       "      <td>-446.612606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9675 rows × 8 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T02:46:57.746877Z",
     "start_time": "2024-09-25T02:46:57.681199Z"
    }
   },
   "cell_type": "code",
   "source": "patient_bounding_boxes.to_csv('../../data/SpineNet/bounding_boxes_3d.csv', index=False)",
   "id": "a6e6e4386a85dc82",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "216d6b0fac2a9d59",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
