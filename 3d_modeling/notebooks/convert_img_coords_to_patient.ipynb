{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T02:44:56.031065Z",
     "start_time": "2024-09-25T02:44:36.581076Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Victor\\.conda\\envs\\python-doodles\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Victor\\.conda\\envs\\python-doodles\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Detection Model...\n",
      "==> Loading model trained for 436 epochs...\n",
      "Loading Appearance Model...\n",
      "==> Loading model trained for 188 epochs...\n",
      "Loading Context Model...\n",
      "==> Loading model trained for 17 epochs...\n",
      "Loading Grading Model...\n",
      "==> Loading model trained for 2 epochs...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pydicom import dcmread\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, '../../data/SpineNet')\n",
    "import spinenet\n",
    "from spinenet import SpineNet, download_example_scan\n",
    "from spinenet.io import load_dicoms_from_folder\n",
    "\n",
    "spnt = SpineNet(device='cuda:0', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc4d7c199292c023",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T02:44:56.036460Z",
     "start_time": "2024-09-25T02:44:56.032070Z"
    }
   },
   "outputs": [],
   "source": [
    "LEVELS = [\"L1\", \"L2\", \"L3\", \"L4\", \"L5\", \"S1\"]\n",
    "COLORS = {\n",
    "    \"L1\": \"red\",\n",
    "    \"L2\": \"blue\",\n",
    "    \"L3\": \"green\",\n",
    "    \"L4\": \"yellow\",\n",
    "    \"L5\": \"white\",\n",
    "    \"S1\": \"purple\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1edbbde9d31b2e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T02:44:56.071317Z",
     "start_time": "2024-09-25T02:44:56.037489Z"
    }
   },
   "outputs": [],
   "source": [
    "train_descs_path = \"../../data/rsna-2024-lumbar-spine-degenerative-classification/train_series_descriptions.csv\"\n",
    "train_images_path = \"../../data/rsna-2024-lumbar-spine-degenerative-classification/train_images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c519efa461b9a378",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T02:44:56.096465Z",
     "start_time": "2024-09-25T02:44:56.072828Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>series_id</th>\n",
       "      <th>series_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4003253</td>\n",
       "      <td>1054713880</td>\n",
       "      <td>Sagittal T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4646740</td>\n",
       "      <td>3486248476</td>\n",
       "      <td>Sagittal T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7143189</td>\n",
       "      <td>3219733239</td>\n",
       "      <td>Sagittal T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8785691</td>\n",
       "      <td>1570286759</td>\n",
       "      <td>Sagittal T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10728036</td>\n",
       "      <td>2399638375</td>\n",
       "      <td>Sagittal T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6281</th>\n",
       "      <td>4282019580</td>\n",
       "      <td>3029774733</td>\n",
       "      <td>Sagittal T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6283</th>\n",
       "      <td>4283570761</td>\n",
       "      <td>2708429184</td>\n",
       "      <td>Sagittal T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6285</th>\n",
       "      <td>4284048608</td>\n",
       "      <td>1875151370</td>\n",
       "      <td>Sagittal T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6288</th>\n",
       "      <td>4287160193</td>\n",
       "      <td>327893304</td>\n",
       "      <td>Sagittal T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6293</th>\n",
       "      <td>4290709089</td>\n",
       "      <td>4237840455</td>\n",
       "      <td>Sagittal T1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1980 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        study_id   series_id series_description\n",
       "1        4003253  1054713880        Sagittal T1\n",
       "4        4646740  3486248476        Sagittal T1\n",
       "8        7143189  3219733239        Sagittal T1\n",
       "10       8785691  1570286759        Sagittal T1\n",
       "14      10728036  2399638375        Sagittal T1\n",
       "...          ...         ...                ...\n",
       "6281  4282019580  3029774733        Sagittal T1\n",
       "6283  4283570761  2708429184        Sagittal T1\n",
       "6285  4284048608  1875151370        Sagittal T1\n",
       "6288  4287160193   327893304        Sagittal T1\n",
       "6293  4290709089  4237840455        Sagittal T1\n",
       "\n",
       "[1980 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_descs = pd.read_csv(train_descs_path)\n",
    "train_descs = train_descs[train_descs[\"series_description\"] == \"Sagittal T1\"]\n",
    "train_descs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2b3e1a41508752f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T02:44:56.105276Z",
     "start_time": "2024-09-25T02:44:56.099204Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_centers(data):\n",
    "    centers = {}\n",
    "    for item in data:\n",
    "        level = item[\"predicted_label\"]\n",
    "        if level in LEVELS:\n",
    "            average_polygon = item[\"average_polygon\"]\n",
    "            centroid_x = np.mean(average_polygon[:, 0])\n",
    "            centroid_y = np.mean(average_polygon[:, 1])\n",
    "            centroid_z = item[\"slice_nos\"][len(item[\"slice_nos\"])//2]\n",
    "            centers[level] = (centroid_x, centroid_y, centroid_z)\n",
    "    return centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0efe7bba8ec7be5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T02:44:56.111850Z",
     "start_time": "2024-09-25T02:44:56.107406Z"
    }
   },
   "outputs": [],
   "source": [
    "centers_per_study = {\n",
    "    \"study_id\": [],\n",
    "    \"series_id\": [],\n",
    "    \"x\": [],\n",
    "    \"y\": [],\n",
    "    \"instance_number\": [],\n",
    "    \"level\": []\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d60daf4b3a9b230",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T02:46:12.088883Z",
     "start_time": "2024-09-25T02:44:56.113855Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [01:14, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m scan \u001b[38;5;241m=\u001b[39m load_dicoms_from_folder(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_images_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstudy_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseries_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, require_extensions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m num_slices \u001b[38;5;241m=\u001b[39m scan\u001b[38;5;241m.\u001b[39mvolume\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m----> 7\u001b[0m vert_dicts \u001b[38;5;241m=\u001b[39m spnt\u001b[38;5;241m.\u001b[39mdetect_vb(scan\u001b[38;5;241m.\u001b[39mvolume, scan\u001b[38;5;241m.\u001b[39mpixel_spacing)\n\u001b[0;32m      8\u001b[0m centers \u001b[38;5;241m=\u001b[39m calculate_centers(vert_dicts)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m level \u001b[38;5;129;01min\u001b[39;00m centers:\n",
      "File \u001b[1;32mD:\\Users\\Victor\\Documents\\python-doodles\\rsna-2024\\notebooks\\../../data/SpineNet\\spinenet\\main.py:147\u001b[0m, in \u001b[0;36mSpineNet.detect_vb\u001b[1;34m(self, volume, pixel_spacing, debug, penalise_skips, remove_single_slice_detections)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;124;03mUse SpineNet to detect and label vertebral bodies in a volume.\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;124;03m    A list of dictionaries containing the vertebrae labels, their corresponding polygons and the slices in which they appear.\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m volume\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscan should be a 3-dimensional array of shape HxWxS.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 147\u001b[0m detect_ans \u001b[38;5;241m=\u001b[39m detect_and_group(\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdetection_model,\n\u001b[0;32m    149\u001b[0m     volume,\n\u001b[0;32m    150\u001b[0m     remove_excess_black_space\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mremove_black_space,\n\u001b[0;32m    151\u001b[0m     plot_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    152\u001b[0m     using_resnet\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    153\u001b[0m     corner_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcorner_threshold,\n\u001b[0;32m    154\u001b[0m     centroid_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcentroid_threshold,\n\u001b[0;32m    155\u001b[0m     group_across_slices_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroup_across_slices_threshold,\n\u001b[0;32m    156\u001b[0m     remove_single_slice_detections\u001b[38;5;241m=\u001b[39mremove_single_slice_detections,\n\u001b[0;32m    157\u001b[0m     pixel_spacing\u001b[38;5;241m=\u001b[39mpixel_spacing,\n\u001b[0;32m    158\u001b[0m     device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice,\n\u001b[0;32m    159\u001b[0m     debug\u001b[38;5;241m=\u001b[39mdebug,\n\u001b[0;32m    160\u001b[0m )\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m debug:\n\u001b[0;32m    162\u001b[0m     vert_dicts, patches, patches_dicts, detection_dicts, transform_info_dicts \u001b[38;5;241m=\u001b[39m detect_ans\n",
      "File \u001b[1;32mD:\\Users\\Victor\\Documents\\python-doodles\\rsna-2024\\notebooks\\../../data/SpineNet\\spinenet\\utils\\detect_and_group.py:69\u001b[0m, in \u001b[0;36mdetect_and_group\u001b[1;34m(detection_net, scan, remove_excess_black_space, pixel_spacing, plot_outputs, using_resnet, corner_threshold, centroid_threshold, group_across_slices_threshold, remove_single_slice_detections, device, debug)\u001b[0m\n\u001b[0;32m     65\u001b[0m patches, transform_info_dicts \u001b[38;5;241m=\u001b[39m split_into_patches_exhaustive(\n\u001b[0;32m     66\u001b[0m     scan, pixel_spacing\u001b[38;5;241m=\u001b[39mpixel_spacing, overlap_param\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.4\u001b[39m, using_resnet\u001b[38;5;241m=\u001b[39musing_resnet\n\u001b[0;32m     67\u001b[0m )\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# group the detections made in each patch into slice level detections\u001b[39;00m\n\u001b[1;32m---> 69\u001b[0m detection_dicts, patches_dicts \u001b[38;5;241m=\u001b[39m make_in_slice_detections(\n\u001b[0;32m     70\u001b[0m     detection_net,\n\u001b[0;32m     71\u001b[0m     patches,\n\u001b[0;32m     72\u001b[0m     transform_info_dicts,\n\u001b[0;32m     73\u001b[0m     scan\u001b[38;5;241m.\u001b[39mshape,\n\u001b[0;32m     74\u001b[0m     corner_threshold,\n\u001b[0;32m     75\u001b[0m     centroid_threshold,\n\u001b[0;32m     76\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[0;32m     77\u001b[0m )\n\u001b[0;32m     79\u001b[0m vert_dicts \u001b[38;5;241m=\u001b[39m group_slice_detections(\n\u001b[0;32m     80\u001b[0m     detection_dicts,\n\u001b[0;32m     81\u001b[0m     iou_threshold\u001b[38;5;241m=\u001b[39mgroup_across_slices_threshold,\n\u001b[0;32m     82\u001b[0m     remove_single_slice_detections\u001b[38;5;241m=\u001b[39mremove_single_slice_detections,\n\u001b[0;32m     83\u001b[0m )\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m debug:\n",
      "File \u001b[1;32mD:\\Users\\Victor\\Documents\\python-doodles\\rsna-2024\\notebooks\\../../data/SpineNet\\spinenet\\utils\\detection_post_processing.py:52\u001b[0m, in \u001b[0;36mmake_in_slice_detections\u001b[1;34m(detection_net, patches, transform_info_dicts, scan_shape, corner_threshold, centroid_threshold, device)\u001b[0m\n\u001b[0;32m     49\u001b[0m net_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([patches_tensor, flipped_patches_tensor], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;66;03m# both_net_output = detection_net(net_input.to(device).float()).cpu()\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m     net_output \u001b[38;5;241m=\u001b[39m detection_net(patches_tensor\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat())\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[0;32m     54\u001b[0m patches_dicts\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpatches\u001b[39m\u001b[38;5;124m\"\u001b[39m: patches_tensor\u001b[38;5;241m.\u001b[39mnumpy(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnet_output\u001b[39m\u001b[38;5;124m\"\u001b[39m: net_output\u001b[38;5;241m.\u001b[39mnumpy(), \n\u001b[0;32m     55\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlandmark_points\u001b[39m\u001b[38;5;124m\"\u001b[39m: {}, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlandmark_arrows\u001b[39m\u001b[38;5;124m\"\u001b[39m: {}})\n\u001b[0;32m     57\u001b[0m all_corners \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpoints\u001b[39m\u001b[38;5;124m\"\u001b[39m: {}, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marrows\u001b[39m\u001b[38;5;124m\"\u001b[39m: {}}\n",
      "File \u001b[1;32m~\\.conda\\envs\\python-doodles\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\.conda\\envs\\python-doodles\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Users\\Victor\\Documents\\python-doodles\\rsna-2024\\notebooks\\../../data/SpineNet\\spinenet\\models\\vfr.py:170\u001b[0m, in \u001b[0;36mVFRResNetDetector.forward\u001b[1;34m(self, x, with_output_feature_map)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup_blocks, \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    169\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayer_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mVFRResNetDetector\u001b[38;5;241m.\u001b[39mDEPTH\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 170\u001b[0m     x \u001b[38;5;241m=\u001b[39m block(x, pre_pools[key])\n\u001b[0;32m    171\u001b[0m output_feature_map \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m    172\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout(x)\n",
      "File \u001b[1;32m~\\.conda\\envs\\python-doodles\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\.conda\\envs\\python-doodles\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Users\\Victor\\Documents\\python-doodles\\rsna-2024\\notebooks\\../../data/SpineNet\\spinenet\\models\\vfr.py:99\u001b[0m, in \u001b[0;36mUpBlockForUNetWithResNet50.forward\u001b[1;34m(self, up_x, down_x)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, up_x, down_x):\n\u001b[0;32m     93\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \n\u001b[0;32m     95\u001b[0m \u001b[38;5;124;03m    :param up_x: this is the output from the previous up block\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;124;03m    :param down_x: this is the output from the down block\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;124;03m    :return: upsampled feature map\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 99\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupsample(up_x)\n\u001b[0;32m    100\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([x, down_x], \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    101\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_block_1(x)\n",
      "File \u001b[1;32m~\\.conda\\envs\\python-doodles\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\.conda\\envs\\python-doodles\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\python-doodles\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\.conda\\envs\\python-doodles\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\.conda\\envs\\python-doodles\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\python-doodles\\Lib\\site-packages\\torch\\nn\\modules\\upsampling.py:157\u001b[0m, in \u001b[0;36mUpsample.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39minterpolate(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_factor, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malign_corners,\n\u001b[0;32m    158\u001b[0m                          recompute_scale_factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecompute_scale_factor)\n",
      "File \u001b[1;32m~\\.conda\\envs\\python-doodles\\Lib\\site-packages\\torch\\nn\\functional.py:4065\u001b[0m, in \u001b[0;36minterpolate\u001b[1;34m(input, size, scale_factor, mode, align_corners, recompute_scale_factor, antialias)\u001b[0m\n\u001b[0;32m   4059\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mare_deterministic_algorithms_enabled() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mis_cuda:\n\u001b[0;32m   4060\u001b[0m             \u001b[38;5;66;03m# Use slow decomp whose backward will be in terms of index_put\u001b[39;00m\n\u001b[0;32m   4061\u001b[0m             \u001b[38;5;66;03m# importlib is required because the import cannot be top level\u001b[39;00m\n\u001b[0;32m   4062\u001b[0m             \u001b[38;5;66;03m# (cycle) and cannot be nested (TS doesn't support)\u001b[39;00m\n\u001b[0;32m   4063\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch._decomp.decompositions\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39m_upsample_linear_vec(\n\u001b[0;32m   4064\u001b[0m                 \u001b[38;5;28minput\u001b[39m, output_size, align_corners, scale_factors)\n\u001b[1;32m-> 4065\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mupsample_bilinear2d(\u001b[38;5;28minput\u001b[39m, output_size, align_corners, scale_factors)\n\u001b[0;32m   4066\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m5\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrilinear\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   4067\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m align_corners \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for index, row in tqdm(train_descs.iterrows()):\n",
    "    scan = load_dicoms_from_folder(f\"{train_images_path}/{row['study_id']}/{row['series_id']}\", require_extensions=False)\n",
    "    num_slices = scan.volume.shape[-1]\n",
    "\n",
    "    vert_dicts = spnt.detect_vb(scan.volume, scan.pixel_spacing)\n",
    "    centers = calculate_centers(vert_dicts)\n",
    "    \n",
    "    for level in centers:\n",
    "        centers_per_study[\"study_id\"].append(row['study_id'])\n",
    "        centers_per_study[\"series_id\"].append(row['series_id'])\n",
    "        centers_per_study[\"level\"].append(level)\n",
    "        \n",
    "        centers_per_study[\"x\"].append(centers[level][0])\n",
    "        centers_per_study[\"y\"].append(centers[level][1])\n",
    "        centers_per_study[\"instance_number\"].append(centers[level][2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63c8139871f29d9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>series_id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>instance_number</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [study_id, series_id, x, y, instance_number, level]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centers_per_study = pd.DataFrame.from_dict(centers_per_study)\n",
    "centers_per_study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b234263cfe5a72c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T02:46:12.092397Z",
     "start_time": "2024-09-25T02:46:12.090891Z"
    }
   },
   "outputs": [],
   "source": [
    "centers_per_study.to_csv('../../data/SpineNet/centers_per_study.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ab8dd6e58f6b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_coords_to_patient(x, y, dicom_slice):\n",
    "    \n",
    "    # transform_matrix_factor = np.matrix(\n",
    "    #     [[0, 1, 0, 0],\n",
    "    #      [1, 0, 0, 0],\n",
    "    #      [0, 0, 1, 0],\n",
    "    #      [0, 0, 0, 1]]\n",
    "    # )\n",
    "        \n",
    "    dX, dY = dicom_slice.PixelSpacing\n",
    "    \n",
    "    X = np.array(list(dicom_slice.ImageOrientationPatient[:3]) + [0]) * dY\n",
    "    Y = np.array(list(dicom_slice.ImageOrientationPatient[3:]) + [0]) * dX\n",
    "\n",
    "    S = np.array(list(dicom_slice.ImagePositionPatient) + [1])\n",
    "\n",
    "    transform_matrix = np.array([Y, X, np.zeros(len(X)), S]).T\n",
    "    # transform_matrix = transform_matrix @ transform_matrix_factor\n",
    "\n",
    "    return (transform_matrix @ np.array([y, x, 0, 1]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3782397c5b906a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_basepath = \"../../data/rsna-2024-lumbar-spine-degenerative-classification/train_images\"\n",
    "\n",
    "patient_coords_dict = {\n",
    "    \"study_id\": [],\n",
    "    \"level\": [],\n",
    "    \"x\": [],\n",
    "    \"y\": [],\n",
    "    \"z\": []\n",
    "}\n",
    "\n",
    "for index, group in centers_per_study.groupby(\"study_id\"):\n",
    "    for row_index, row in group.iterrows():\n",
    "        dicom_slice_path = f\"{train_images_basepath}/{row['study_id']}/{row['series_id']}/{row['instance_number']}.dcm\"\n",
    "        dicom_slice = dcmread(dicom_slice_path)\n",
    "        coords = convert_coords_to_patient(row['x'], row['y'], dicom_slice)\n",
    "        \n",
    "        patient_coords_dict[\"study_id\"].append(row['study_id'])\n",
    "        patient_coords_dict[\"level\"].append(row['level'])\n",
    "        patient_coords_dict[\"x\"].append(coords[0])\n",
    "        patient_coords_dict[\"y\"].append(coords[1])\n",
    "        patient_coords_dict[\"z\"].append(coords[2])\n",
    "    \n",
    "patient_coords = pd.DataFrame.from_dict(patient_coords_dict)\n",
    "patient_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39142bfef40f99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_coords.to_csv('../../data/SpineNet/coords_3d.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1e89fa8a50992c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T02:46:52.109051Z",
     "start_time": "2024-09-25T02:46:52.070853Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>level</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4003253</td>\n",
       "      <td>L1</td>\n",
       "      <td>2.192236</td>\n",
       "      <td>57.393290</td>\n",
       "      <td>-373.897314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4003253</td>\n",
       "      <td>L2</td>\n",
       "      <td>2.417129</td>\n",
       "      <td>55.910159</td>\n",
       "      <td>-405.982332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4003253</td>\n",
       "      <td>L3</td>\n",
       "      <td>2.663579</td>\n",
       "      <td>53.663727</td>\n",
       "      <td>-441.036977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4003253</td>\n",
       "      <td>L4</td>\n",
       "      <td>2.900401</td>\n",
       "      <td>54.755404</td>\n",
       "      <td>-475.276522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4003253</td>\n",
       "      <td>L5</td>\n",
       "      <td>-1.697765</td>\n",
       "      <td>63.999043</td>\n",
       "      <td>-505.892668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11844</th>\n",
       "      <td>4290709089</td>\n",
       "      <td>L2</td>\n",
       "      <td>1.119082</td>\n",
       "      <td>47.663407</td>\n",
       "      <td>-359.280225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11845</th>\n",
       "      <td>4290709089</td>\n",
       "      <td>L3</td>\n",
       "      <td>0.473506</td>\n",
       "      <td>40.302511</td>\n",
       "      <td>-394.637869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11846</th>\n",
       "      <td>4290709089</td>\n",
       "      <td>L4</td>\n",
       "      <td>-0.206997</td>\n",
       "      <td>39.813034</td>\n",
       "      <td>-429.821794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11847</th>\n",
       "      <td>4290709089</td>\n",
       "      <td>L5</td>\n",
       "      <td>-0.924925</td>\n",
       "      <td>46.765941</td>\n",
       "      <td>-464.796865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11848</th>\n",
       "      <td>4290709089</td>\n",
       "      <td>S1</td>\n",
       "      <td>-1.612741</td>\n",
       "      <td>66.485341</td>\n",
       "      <td>-494.556885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11849 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         study_id level         x          y           z\n",
       "0         4003253    L1  2.192236  57.393290 -373.897314\n",
       "1         4003253    L2  2.417129  55.910159 -405.982332\n",
       "2         4003253    L3  2.663579  53.663727 -441.036977\n",
       "3         4003253    L4  2.900401  54.755404 -475.276522\n",
       "4         4003253    L5 -1.697765  63.999043 -505.892668\n",
       "...           ...   ...       ...        ...         ...\n",
       "11844  4290709089    L2  1.119082  47.663407 -359.280225\n",
       "11845  4290709089    L3  0.473506  40.302511 -394.637869\n",
       "11846  4290709089    L4 -0.206997  39.813034 -429.821794\n",
       "11847  4290709089    L5 -0.924925  46.765941 -464.796865\n",
       "11848  4290709089    S1 -1.612741  66.485341 -494.556885\n",
       "\n",
       "[11849 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_coords = pd.read_csv('../../data/SpineNet/coords_3d.csv')\n",
    "patient_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "572df26a1fc07fc0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T02:46:56.796797Z",
     "start_time": "2024-09-25T02:46:52.782269Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>level</th>\n",
       "      <th>x_min</th>\n",
       "      <th>y_min</th>\n",
       "      <th>z_min</th>\n",
       "      <th>x_max</th>\n",
       "      <th>y_max</th>\n",
       "      <th>z_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4003253</td>\n",
       "      <td>l1_L2</td>\n",
       "      <td>-26.748936</td>\n",
       "      <td>55.910159</td>\n",
       "      <td>-407.243662</td>\n",
       "      <td>31.358301</td>\n",
       "      <td>81.460212</td>\n",
       "      <td>-372.635984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4003253</td>\n",
       "      <td>l2_L3</td>\n",
       "      <td>-39.236392</td>\n",
       "      <td>53.663727</td>\n",
       "      <td>-443.294215</td>\n",
       "      <td>44.317100</td>\n",
       "      <td>90.528252</td>\n",
       "      <td>-403.725094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4003253</td>\n",
       "      <td>l3_L4</td>\n",
       "      <td>-37.888604</td>\n",
       "      <td>53.663727</td>\n",
       "      <td>-476.392443</td>\n",
       "      <td>43.452585</td>\n",
       "      <td>88.511545</td>\n",
       "      <td>-439.921056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4003253</td>\n",
       "      <td>l4_L5</td>\n",
       "      <td>-39.486138</td>\n",
       "      <td>54.755404</td>\n",
       "      <td>-515.998212</td>\n",
       "      <td>40.688774</td>\n",
       "      <td>93.776126</td>\n",
       "      <td>-465.170979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4003253</td>\n",
       "      <td>l5_S1</td>\n",
       "      <td>-41.433198</td>\n",
       "      <td>63.999043</td>\n",
       "      <td>-552.626305</td>\n",
       "      <td>38.206247</td>\n",
       "      <td>110.521024</td>\n",
       "      <td>-486.731257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9670</th>\n",
       "      <td>4290709089</td>\n",
       "      <td>l1_L2</td>\n",
       "      <td>-41.967984</td>\n",
       "      <td>47.663407</td>\n",
       "      <td>-370.020682</td>\n",
       "      <td>44.810725</td>\n",
       "      <td>92.642828</td>\n",
       "      <td>-314.316335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9671</th>\n",
       "      <td>4290709089</td>\n",
       "      <td>l2_L3</td>\n",
       "      <td>-42.634240</td>\n",
       "      <td>40.302511</td>\n",
       "      <td>-402.023415</td>\n",
       "      <td>44.226828</td>\n",
       "      <td>82.770085</td>\n",
       "      <td>-351.894680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9672</th>\n",
       "      <td>4290709089</td>\n",
       "      <td>l3_L4</td>\n",
       "      <td>-42.223856</td>\n",
       "      <td>39.813034</td>\n",
       "      <td>-430.441901</td>\n",
       "      <td>42.490365</td>\n",
       "      <td>75.261925</td>\n",
       "      <td>-394.017763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9673</th>\n",
       "      <td>4290709089</td>\n",
       "      <td>l4_L5</td>\n",
       "      <td>-33.430330</td>\n",
       "      <td>39.813034</td>\n",
       "      <td>-469.866983</td>\n",
       "      <td>32.298409</td>\n",
       "      <td>73.371890</td>\n",
       "      <td>-424.751677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9674</th>\n",
       "      <td>4290709089</td>\n",
       "      <td>l5_S1</td>\n",
       "      <td>-43.380167</td>\n",
       "      <td>46.765941</td>\n",
       "      <td>-513.885790</td>\n",
       "      <td>40.842501</td>\n",
       "      <td>95.370467</td>\n",
       "      <td>-445.467960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9675 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        study_id  level      x_min      y_min       z_min      x_max  \\\n",
       "0        4003253  l1_L2 -26.748936  55.910159 -407.243662  31.358301   \n",
       "1        4003253  l2_L3 -39.236392  53.663727 -443.294215  44.317100   \n",
       "2        4003253  l3_L4 -37.888604  53.663727 -476.392443  43.452585   \n",
       "3        4003253  l4_L5 -39.486138  54.755404 -515.998212  40.688774   \n",
       "4        4003253  l5_S1 -41.433198  63.999043 -552.626305  38.206247   \n",
       "...          ...    ...        ...        ...         ...        ...   \n",
       "9670  4290709089  l1_L2 -41.967984  47.663407 -370.020682  44.810725   \n",
       "9671  4290709089  l2_L3 -42.634240  40.302511 -402.023415  44.226828   \n",
       "9672  4290709089  l3_L4 -42.223856  39.813034 -430.441901  42.490365   \n",
       "9673  4290709089  l4_L5 -33.430330  39.813034 -469.866983  32.298409   \n",
       "9674  4290709089  l5_S1 -43.380167  46.765941 -513.885790  40.842501   \n",
       "\n",
       "           y_max       z_max  \n",
       "0      81.460212 -372.635984  \n",
       "1      90.528252 -403.725094  \n",
       "2      88.511545 -439.921056  \n",
       "3      93.776126 -465.170979  \n",
       "4     110.521024 -486.731257  \n",
       "...          ...         ...  \n",
       "9670   92.642828 -314.316335  \n",
       "9671   82.770085 -351.894680  \n",
       "9672   75.261925 -394.017763  \n",
       "9673   73.371890 -424.751677  \n",
       "9674   95.370467 -445.467960  \n",
       "\n",
       "[9675 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_bounding_boxes_dict = {\n",
    "    \"study_id\": [],\n",
    "    \"level\": [],\n",
    "    \"x_min\": [],\n",
    "    \"y_min\": [],\n",
    "    \"z_min\": [],\n",
    "    \"x_max\": [],\n",
    "    \"y_max\": [],\n",
    "    \"z_max\": [],\n",
    "}\n",
    "\n",
    "for index, group in patient_coords.groupby(\"study_id\"):\n",
    "    ordered_group = group.sort_values(by=\"level\", ascending=True)\n",
    "    if len(ordered_group) != 6:\n",
    "        continue\n",
    "    for level_index in range(5):\n",
    "        patient_bounding_boxes_dict[\"study_id\"].append(ordered_group['study_id'].iloc[0])\n",
    "        level_label = ordered_group['level'].iloc[level_index].lower() + \"_\" + ordered_group['level'].iloc[level_index + 1] \n",
    "        patient_bounding_boxes_dict[\"level\"].append(level_label)\n",
    "        \n",
    "        # Middle vertebra points\n",
    "        pt_0 = np.array(ordered_group.iloc[level_index][[\"x\", \"y\", \"z\"]])\n",
    "        pt_1 = np.array(ordered_group.iloc[level_index + 1][[\"x\", \"y\", \"z\"]])\n",
    "        \n",
    "        # Distance vector to the next vertebra\n",
    "        d_vec = np.array(pt_0 - pt_1)\n",
    "        d_size = np.linalg.norm(d_vec)\n",
    "        d_unit = d_vec / d_size\n",
    "        \n",
    "        \n",
    "        # Get a pair of orthogonal vectors to find x and y boundary candidates\n",
    "        orth_1 = np.random.randn(3).astype(np.float64)\n",
    "        orth_1 = orth_1 - orth_1.dot(d_unit) * d_unit\n",
    "        orth_1 = orth_1 / np.linalg.norm(orth_1)\n",
    "        \n",
    "        orth_1 = orth_1.astype(np.float64)\n",
    "        d_unit = d_unit.astype(np.float64)\n",
    "        \n",
    "        orth_2 = np.cross(orth_1, d_unit)\n",
    "        orth_2 = orth_2.astype(np.float64)\n",
    "        \n",
    "        orth_1 *= d_size\n",
    "        orth_2 *= d_size\n",
    "        \n",
    "        # Get candidate points (10 of them, 2 per orthogonal per each vertebra center, and the centers themselves)\n",
    "        c_pts = np.array([pt - vec for pt in (pt_0, pt_1) for vec in (orth_1, orth_2)] + \n",
    "                         [pt + vec for pt in (pt_0, pt_1) for vec in (orth_1, orth_2)] +\n",
    "                         [pt_0, pt_1])\n",
    "        \n",
    "        # x_min and x_max are just the min and max from all this\n",
    "        x_min = np.min(c_pts[:, 0])\n",
    "        x_max = np.max(c_pts[:, 0])\n",
    "        \n",
    "        x_delta = x_max - x_min\n",
    "        \n",
    "        # y_max is going to be over the center ys\n",
    "        # And we're going to get y_min by getting y_min over c_pts and then extending the y_min over center ys\n",
    "        c_pts_y_min = np.min(c_pts[:, 1])\n",
    "        c_pts_y_max = np.max(c_pts[:, 1])\n",
    "\n",
    "        y_max = max(pt_0[1], pt_1[1])\n",
    "        y_min = min(pt_0[1], pt_1[1])\n",
    "        \n",
    "        y_max += abs(c_pts_y_max - y_max)\n",
    "    \n",
    "        # z_max and z_min will be the same as x_min and x_max\n",
    "        z_min = np.min(c_pts[:, 2])\n",
    "        z_max = np.max(c_pts[:, 2])    \n",
    "        \n",
    "        patient_bounding_boxes_dict[\"x_min\"].append(x_min)\n",
    "        patient_bounding_boxes_dict[\"y_min\"].append(y_min)\n",
    "        patient_bounding_boxes_dict[\"z_min\"].append(z_min)\n",
    "        patient_bounding_boxes_dict[\"x_max\"].append(x_max)\n",
    "        patient_bounding_boxes_dict[\"y_max\"].append(y_max)\n",
    "        patient_bounding_boxes_dict[\"z_max\"].append(z_max)\n",
    "\n",
    "patient_bounding_boxes = pd.DataFrame.from_dict(patient_bounding_boxes_dict)\n",
    "patient_bounding_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6e6e4386a85dc82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T02:46:57.746877Z",
     "start_time": "2024-09-25T02:46:57.681199Z"
    }
   },
   "outputs": [],
   "source": [
    "patient_bounding_boxes.to_csv('../../data/SpineNet/bounding_boxes_3d.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216d6b0fac2a9d59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
