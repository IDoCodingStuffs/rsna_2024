{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "from rsna_dataloader import *\n",
    "import torchio as tio\n",
    "\n",
    "DATA_BASEPATH = \"../data/rsna-2024-lumbar-spine-degenerative-classification/\"\n",
    "TRAINING_DATA = retrieve_coordinate_training_data(DATA_BASEPATH)\n",
    "\n",
    "transform_3d_val = tio.Compose([\n",
    "    tio.Resize((128, 128, 128), image_interpolation=\"bspline\"),\n",
    "    tio.RescaleIntensity(out_min_max=(0, 1)),\n",
    "])\n",
    "\n",
    "(trainloader, valloader, test_loader,\n",
    " trainset, valset, testset) = create_subject_level_datasets_and_loaders(TRAINING_DATA,\n",
    "                                                                        transform_3d_train=transform_3d_val,\n",
    "                                                                        transform_3d_val=transform_3d_val,\n",
    "                                                                        base_path=os.path.join(\n",
    "                                                                            DATA_BASEPATH,\n",
    "                                                                            \"train_images\"),\n",
    "                                                                        num_workers=0,\n",
    "                                                                        split_factor=0.3,\n",
    "                                                                        batch_size=1,\n",
    "                                                                        )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-20T00:08:11.948488Z",
     "start_time": "2024-07-20T00:08:10.681197Z"
    }
   },
   "id": "e9ac9fb7e982b463",
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'VisibleDeprecationWarning' from 'numpy' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "File \u001B[1;32m~\\anaconda3\\envs\\rsna-2024\\Lib\\site-packages\\matplotlib\\cbook.py:27\u001B[0m\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 27\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexceptions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m VisibleDeprecationWarning  \u001B[38;5;66;03m# numpy >= 1.25\u001B[39;00m\n\u001B[0;32m     28\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m:\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'numpy.exceptions'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mrsna_dataloader\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorchio\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtio\u001B[39;00m\n\u001B[0;32m      4\u001B[0m DATA_BASEPATH \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../data/rsna-2024-lumbar-spine-degenerative-classification/\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[1;32m~\\Documents\\python-doodles\\rsna-2024\\rsna_dataloader.py:3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mrandom\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mos\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\rsna-2024\\Lib\\site-packages\\matplotlib\\__init__.py:172\u001B[0m\n\u001B[0;32m    168\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpackaging\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mversion\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m parse \u001B[38;5;28;01mas\u001B[39;00m parse_version\n\u001B[0;32m    170\u001B[0m \u001B[38;5;66;03m# cbook must import matplotlib only within function\u001B[39;00m\n\u001B[0;32m    171\u001B[0m \u001B[38;5;66;03m# definitions, so it is safe to import from it here.\u001B[39;00m\n\u001B[1;32m--> 172\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _api, _version, cbook, _docstring, rcsetup\n\u001B[0;32m    173\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcbook\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m sanitize_sequence\n\u001B[0;32m    174\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_api\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m MatplotlibDeprecationWarning\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\rsna-2024\\Lib\\site-packages\\matplotlib\\cbook.py:29\u001B[0m\n\u001B[0;32m     27\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexceptions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m VisibleDeprecationWarning  \u001B[38;5;66;03m# numpy >= 1.25\u001B[39;00m\n\u001B[0;32m     28\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m:\n\u001B[1;32m---> 29\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m VisibleDeprecationWarning\n\u001B[0;32m     31\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\n\u001B[0;32m     32\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _api, _c_internal_utils\n",
      "\u001B[1;31mImportError\u001B[0m: cannot import name 'VisibleDeprecationWarning' from 'numpy' (unknown location)"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "TEST_DATA = TRAINING_DATA[TRAINING_DATA[\"study_id\"].isin(testset.subjects[\"study_id\"].values)]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6697134fa029e912",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def convert_train_data_to_solution(train_df):\n",
    "    ret = train_df.loc[:,[\"row_id\", \"severity\"]]\n",
    "    ret[\"normal_mild\"] = 0\n",
    "    ret[\"moderate\"] = 0\n",
    "    ret[\"severe\"] = 0\n",
    "    ret[\"sample_weight\"] = 1\n",
    "    \n",
    "    for index, row in ret.iterrows():\n",
    "        ret.loc[index, row[\"severity\"]] = 1\n",
    "        if row[\"severity\"] == \"normal_mild\":\n",
    "            ret.loc[index, \"sample_weight\"] = 1\n",
    "        elif row[\"severity\"] == \"moderate\":\n",
    "            ret.loc[index, \"sample_weight\"] = 2\n",
    "        elif row[\"severity\"] == \"severe\":\n",
    "            ret.loc[index, \"sample_weight\"] = 3\n",
    "        else:\n",
    "            print(row[\"severity\"])\n",
    "\n",
    "            \n",
    "    return ret[[\"row_id\", \"normal_mild\", \"moderate\", \"severe\", \"sample_weight\"]]\n",
    "\n",
    "\n",
    "test_solution = convert_train_data_to_solution(TEST_DATA)\n",
    "test_solution[test_solution[\"severe\"] == 1]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "651aedcf688b7e97",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d266af16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T02:57:17.269612Z",
     "iopub.status.busy": "2024-07-14T02:57:17.268783Z",
     "iopub.status.idle": "2024-07-14T02:57:17.275718Z",
     "shell.execute_reply": "2024-07-14T02:57:17.274380Z"
    },
    "papermill": {
     "duration": 0.018323,
     "end_time": "2024-07-14T02:57:17.277995",
     "exception": false,
     "start_time": "2024-07-14T02:57:17.259672",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def retrieve_image_paths(base_path, study_id, series_id):\n",
    "    series_dir = os.path.join(base_path, str(study_id), str(series_id))\n",
    "    images = os.listdir(series_dir)\n",
    "    image_paths = [os.path.join(series_dir, img) for img in images]\n",
    "    return image_paths"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3e75c1ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T02:57:17.294659Z",
     "iopub.status.busy": "2024-07-14T02:57:17.294223Z",
     "iopub.status.idle": "2024-07-14T02:57:24.345234Z",
     "shell.execute_reply": "2024-07-14T02:57:24.344172Z"
    },
    "papermill": {
     "duration": 7.06268,
     "end_time": "2024-07-14T02:57:24.348203",
     "exception": false,
     "start_time": "2024-07-14T02:57:17.285523",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchio as tio\n",
    "import albumentations\n",
    "import cv2\n",
    "import pydicom\n",
    "import itk\n",
    "\n",
    "CONDITIONS = {\n",
    "    \"Sagittal T2/STIR\": [\"Spinal Canal Stenosis\"],\n",
    "    \"Axial T2\": [\"Left Subarticular Stenosis\", \"Right Subarticular Stenosis\"],\n",
    "    \"Sagittal T1\": [\"Left Neural Foraminal Narrowing\", \"Right Neural Foraminal Narrowing\"],\n",
    "}\n",
    "\n",
    "\n",
    "def read_series_as_volume(dirName, verbose=False):\n",
    "    PixelType = itk.ctype(\"signed short\")\n",
    "    Dimension = 3\n",
    "\n",
    "    ImageType = itk.Image[PixelType, Dimension]\n",
    "\n",
    "    namesGenerator = itk.GDCMSeriesFileNames.New()\n",
    "    namesGenerator.SetUseSeriesDetails(True)\n",
    "    namesGenerator.AddSeriesRestriction(\"0008|0021\")\n",
    "    namesGenerator.SetGlobalWarningDisplay(False)\n",
    "    namesGenerator.SetDirectory(dirName)\n",
    "\n",
    "    seriesUID = namesGenerator.GetSeriesUIDs()\n",
    "\n",
    "    if verbose:\n",
    "        if len(seriesUID) < 1:\n",
    "            print(\"No DICOMs in: \" + dirName)\n",
    "\n",
    "        print(\"The directory: \" + dirName)\n",
    "        print(\"Contains the following DICOM Series: \")\n",
    "        for uid in seriesUID:\n",
    "            print(uid)\n",
    "\n",
    "    reader = None\n",
    "    dicomIO = None\n",
    "    for i in range(10):\n",
    "        for uid in seriesUID:\n",
    "            seriesIdentifier = uid\n",
    "            if verbose:\n",
    "                print(\"Reading: \" + seriesIdentifier)\n",
    "            fileNames = namesGenerator.GetFileNames(seriesIdentifier)\n",
    "\n",
    "            reader = itk.ImageSeriesReader[ImageType].New()\n",
    "            dicomIO = itk.GDCMImageIO.New()\n",
    "            reader.SetImageIO(dicomIO)\n",
    "            reader.SetFileNames(fileNames)\n",
    "            reader.ForceOrthogonalDirectionOff()\n",
    "        if reader is not None:\n",
    "            break\n",
    "\n",
    "    if reader is None or dicomIO is None:\n",
    "        raise FileNotFoundError(f\"Empty path? {os.path.abspath(dirName)}\")\n",
    "    reader.Update()\n",
    "    data = itk.GetArrayFromImage(reader.GetOutput())\n",
    "\n",
    "    del namesGenerator\n",
    "    del dicomIO\n",
    "    del reader\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "class PatientLevelTestset(Dataset):\n",
    "    def __init__(self,\n",
    "                 base_path: str,\n",
    "                 dataframe: pd.DataFrame,\n",
    "                 transform_3d=None):\n",
    "        self.base_path = base_path\n",
    "\n",
    "        self.dataframe = (dataframe[['study_id', \"series_id\", \"series_description\"]]\n",
    "                          .drop_duplicates())\n",
    "\n",
    "        self.subjects = self.dataframe[['study_id']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "        self.transform_3d = transform_3d\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subjects)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        curr = self.subjects.iloc[index]\n",
    "        images_basepath = os.path.join(self.base_path, str(curr[\"study_id\"]))\n",
    "        images = []\n",
    "\n",
    "        for series_desc in CONDITIONS.keys():\n",
    "            # !TODO: Multiple matching series\n",
    "            series = self.dataframe.loc[\n",
    "                (self.dataframe[\"study_id\"] == curr[\"study_id\"]) &\n",
    "                (self.dataframe[\"series_description\"] == series_desc)].sort_values(\"series_id\")['series_id'].iloc[0]\n",
    "\n",
    "            series_path = os.path.join(images_basepath, str(series))\n",
    "            series_images = read_series_as_volume(series_path)\n",
    "\n",
    "            if self.transform_3d is not None:\n",
    "                series_images = self.transform_3d(np.expand_dims(series_images, 0))  #.data\n",
    "\n",
    "            images.append(torch.Tensor(series_images).squeeze(0))\n",
    "\n",
    "        return torch.stack(images), curr[\"study_id\"]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b6d4e1e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T02:57:24.364879Z",
     "iopub.status.busy": "2024-07-14T02:57:24.364274Z",
     "iopub.status.idle": "2024-07-14T02:57:24.370349Z",
     "shell.execute_reply": "2024-07-14T02:57:24.369321Z"
    },
    "papermill": {
     "duration": 0.017043,
     "end_time": "2024-07-14T02:57:24.372857",
     "exception": false,
     "start_time": "2024-07-14T02:57:24.355814",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "transform_3d = tio.Compose([\n",
    "    tio.Resize((144, 144, 144), image_interpolation=\"bspline\"),\n",
    "    tio.RescaleIntensity(out_min_max=(0, 1)),\n",
    "])\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c1ab6084",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T02:57:24.389957Z",
     "iopub.status.busy": "2024-07-14T02:57:24.388948Z",
     "iopub.status.idle": "2024-07-14T02:57:24.395679Z",
     "shell.execute_reply": "2024-07-14T02:57:24.394617Z"
    },
    "papermill": {
     "duration": 0.01775,
     "end_time": "2024-07-14T02:57:24.398158",
     "exception": false,
     "start_time": "2024-07-14T02:57:24.380408",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "def create_subject_level_testset_and_loader(df: pd.DataFrame,\n",
    "                                            transform_3d,\n",
    "                                            base_path: str,\n",
    "                                            batch_size=1,\n",
    "                                            num_workers=0):\n",
    "    testset = PatientLevelTestset(base_path, df, transform_3d=transform_3d)\n",
    "    test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "    return testset, test_loader"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "537b93b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T02:57:24.414785Z",
     "iopub.status.busy": "2024-07-14T02:57:24.414339Z",
     "iopub.status.idle": "2024-07-14T02:57:24.434238Z",
     "shell.execute_reply": "2024-07-14T02:57:24.433003Z"
    },
    "papermill": {
     "duration": 0.031391,
     "end_time": "2024-07-14T02:57:24.437093",
     "exception": false,
     "start_time": "2024-07-14T02:57:24.405702",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "import os\n",
    "\n",
    "dataset, dataloader = create_subject_level_testset_and_loader(TEST_DATA, transform_3d,\n",
    "                                                              os.path.join(DATA_BASEPATH, \"train_images\"))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "86b235b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T02:57:24.454261Z",
     "iopub.status.busy": "2024-07-14T02:57:24.453596Z",
     "iopub.status.idle": "2024-07-14T02:57:24.521674Z",
     "shell.execute_reply": "2024-07-14T02:57:24.520545Z"
    },
    "papermill": {
     "duration": 0.07944,
     "end_time": "2024-07-14T02:57:24.524068",
     "exception": false,
     "start_time": "2024-07-14T02:57:24.444628",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a5a4217d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T02:57:24.541361Z",
     "iopub.status.busy": "2024-07-14T02:57:24.540336Z",
     "iopub.status.idle": "2024-07-14T02:57:27.765557Z",
     "shell.execute_reply": "2024-07-14T02:57:27.764607Z"
    },
    "papermill": {
     "duration": 3.236629,
     "end_time": "2024-07-14T02:57:27.768268",
     "exception": false,
     "start_time": "2024-07-14T02:57:24.531639",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "import torch.nn as nn\n",
    "import timm_3d\n",
    "\n",
    "\n",
    "class CNN_Model_3D_Multihead(nn.Module):\n",
    "    def __init__(self, backbone=\"efficientnet_lite0\", in_chans=1, out_classes=5, out_dim=3, pretrained=True):\n",
    "        super(CNN_Model_3D_Multihead, self).__init__()\n",
    "        self.out_classes = out_classes\n",
    "\n",
    "        self.encoder = timm_3d.create_model(\n",
    "            backbone,\n",
    "            num_classes=out_classes * CONFIG[\"out_dim\"],\n",
    "            features_only=False,\n",
    "            drop_rate=CONFIG[\"drop_rate\"],\n",
    "            drop_path_rate=CONFIG[\"drop_path_rate\"],\n",
    "            # drop_rate_last=CONFIG[\"drop_rate_last\"],\n",
    "            pretrained=pretrained,\n",
    "            in_chans=in_chans,\n",
    "        )\n",
    "        head_in_dim = self.encoder.classifier.in_features\n",
    "        self.encoder.classifier = nn.Identity()\n",
    "        self.heads = nn.ModuleList(\n",
    "            [nn.Sequential(\n",
    "                nn.Linear(head_in_dim, 1),\n",
    "                LogisticCumulativeLink(CONFIG[\"out_dim\"])\n",
    "            ) for i in range(out_classes)]\n",
    "        )\n",
    "\n",
    "        self.ascension_callback = AscensionCallback()\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.encoder(x)\n",
    "        return torch.swapaxes(torch.stack([head(feat) for head in self.heads]), 0, 1)\n",
    "\n",
    "    def _ascension_callback(self):\n",
    "        for head in self.heads:\n",
    "            self.ascension_callback.clip(head[1])\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "003ebb15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T02:57:27.786070Z",
     "iopub.status.busy": "2024-07-14T02:57:27.785649Z",
     "iopub.status.idle": "2024-07-14T02:57:29.097389Z",
     "shell.execute_reply": "2024-07-14T02:57:29.096228Z"
    },
    "papermill": {
     "duration": 1.324165,
     "end_time": "2024-07-14T02:57:29.099979",
     "exception": false,
     "start_time": "2024-07-14T02:57:27.775814",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "model = torch.load(\n",
    "    \"../models\\\\tf_efficientnetv2_m_144_3d_spacecutter\\\\tf_efficientnetv2_m_144_3d_spacecutter_35.pt\", map_location=torch.device('cpu')).to(\n",
    "    device)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "17ac90c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T02:57:29.117449Z",
     "iopub.status.busy": "2024-07-14T02:57:29.116463Z",
     "iopub.status.idle": "2024-07-14T02:57:29.126507Z",
     "shell.execute_reply": "2024-07-14T02:57:29.125528Z"
    },
    "papermill": {
     "duration": 0.021371,
     "end_time": "2024-07-14T02:57:29.128991",
     "exception": false,
     "start_time": "2024-07-14T02:57:29.107620",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "CONDITIONS = {\n",
    "    \"Sagittal T2/STIR\": [\"spinal_canal_stenosis\"],\n",
    "    \"Axial T2\": [\"left_subarticular_stenosis\", \"right_subarticular_stenosis\"],\n",
    "    \"Sagittal T1\": [\"left_neural_foraminal_narrowing\", \"right_neural_foraminal_narrowing\"],\n",
    "}\n",
    "\n",
    "ALL_CONDITIONS = sorted([\"spinal_canal_stenosis\", \"left_subarticular_stenosis\", \"right_subarticular_stenosis\",\n",
    "                         \"left_neural_foraminal_narrowing\", \"right_neural_foraminal_narrowing\"])\n",
    "LEVELS = [\"l1_l2\", \"l2_l3\", \"l3_l4\", \"l4_l5\", \"l5_s1\"]\n",
    "\n",
    "results_df = pd.DataFrame({\"row_id\": [], \"normal_mild\": [], \"moderate\": [], \"severe\": []})\n",
    "\n",
    "ALL_CONDITIONS"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "81c45b3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T02:57:29.146436Z",
     "iopub.status.busy": "2024-07-14T02:57:29.145366Z",
     "iopub.status.idle": "2024-07-14T02:57:29.183168Z",
     "shell.execute_reply": "2024-07-14T02:57:29.182040Z"
    },
    "papermill": {
     "duration": 0.049311,
     "end_time": "2024-07-14T02:57:29.185912",
     "exception": false,
     "start_time": "2024-07-14T02:57:29.136601",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Pre-populate results df\n",
    "import glob\n",
    "import os\n",
    "\n",
    "study_ids = TEST_DATA[\"study_id\"].values\n",
    "# study_ids = glob.glob(\"/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images/*\")\n",
    "# study_ids = [os.path.basename(e) for e in study_ids]\n",
    "\n",
    "results_df = pd.DataFrame({\"row_id\": [], \"normal_mild\": [], \"moderate\": [], \"severe\": []})\n",
    "for study_id in study_ids:\n",
    "    for condition in ALL_CONDITIONS:\n",
    "        for level in LEVELS:\n",
    "            row_id = f\"{study_id}_{condition}_{level}\"\n",
    "            results_df = results_df._append(\n",
    "                {\"row_id\": row_id, \"normal_mild\": 1 / 3, \"moderate\": 1 / 3, \"severe\": 1 / 3}, ignore_index=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas.api.types\n",
    "import sklearn.metrics\n",
    "\n",
    "\n",
    "class ParticipantVisibleError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "def get_condition(full_location: str) -> str:\n",
    "    # Given an input like spinal_canal_stenosis_l1_l2 extracts 'spinal'\n",
    "    for injury_condition in ['spinal', 'foraminal', 'subarticular']:\n",
    "        if injury_condition in full_location:\n",
    "            return injury_condition\n",
    "    raise ValueError(f'condition not found in {full_location}')\n",
    "\n",
    "\n",
    "def score(\n",
    "        solution: pd.DataFrame,\n",
    "        submission: pd.DataFrame,\n",
    "        row_id_column_name: str,\n",
    "        any_severe_scalar: float\n",
    "    ) -> float:\n",
    "    '''\n",
    "    Pseudocode:\n",
    "    1. Calculate the sample weighted log loss for each medical condition:\n",
    "    2. Derive a new any_severe label.\n",
    "    3. Calculate the sample weighted log loss for the new any_severe label.\n",
    "    4. Return the average of all of the label group log losses as the final score, normalized for the number of columns in each group.\n",
    "       This mitigates the impact of spinal stenosis having only half as many columns as the other two conditions.\n",
    "    '''\n",
    "\n",
    "    target_levels = ['normal_mild', 'moderate', 'severe']\n",
    "\n",
    "    # Run basic QC checks on the inputs\n",
    "    if not pandas.api.types.is_numeric_dtype(submission[target_levels].values):\n",
    "        raise ParticipantVisibleError('All submission values must be numeric')\n",
    "\n",
    "    if not np.isfinite(submission[target_levels].values).all():\n",
    "        raise ParticipantVisibleError('All submission values must be finite')\n",
    "\n",
    "    if solution[target_levels].min().min() < 0:\n",
    "        raise ParticipantVisibleError('All labels must be at least zero')\n",
    "    if submission[target_levels].min().min() < 0:\n",
    "        raise ParticipantVisibleError('All predictions must be at least zero')\n",
    "\n",
    "    solution['study_id'] = solution['row_id'].apply(lambda x: x.split('_')[0])\n",
    "    solution['location'] = solution['row_id'].apply(lambda x: '_'.join(x.split('_')[1:]))\n",
    "    solution['condition'] = solution['row_id'].apply(get_condition)\n",
    "\n",
    "    # del solution[row_id_column_name]\n",
    "    # del submission[row_id_column_name]\n",
    "    # assert sorted(submission.columns) == sorted(target_levels)\n",
    "    \n",
    "    submission = submission.sort_values(by=\"row_id\")\n",
    "    solution = solution.sort_values(by=\"row_id\")\n",
    "\n",
    "    submission['study_id'] = solution['study_id']\n",
    "    submission['location'] = solution['location']\n",
    "    submission['condition'] = solution['condition']\n",
    "\n",
    "    condition_losses = []\n",
    "    condition_weights = []\n",
    "    for condition in ['spinal', 'foraminal', 'subarticular']:\n",
    "        condition_indices = solution.loc[solution['condition'] == condition].index.values\n",
    "        condition_loss = sklearn.metrics.log_loss(\n",
    "            y_true=solution.loc[condition_indices, target_levels].values,\n",
    "            y_pred=submission.loc[condition_indices, target_levels].values,\n",
    "            sample_weight=solution.loc[condition_indices, 'sample_weight'].values\n",
    "        )\n",
    "        condition_losses.append(condition_loss)\n",
    "        condition_weights.append(1)\n",
    "\n",
    "    any_severe_spinal_labels = pd.Series(solution.loc[solution['condition'] == 'spinal'].groupby('study_id')['severe'].max())\n",
    "    any_severe_spinal_weights = pd.Series(solution.loc[solution['condition'] == 'spinal'].groupby('study_id')['sample_weight'].max())\n",
    "    any_severe_spinal_predictions = pd.Series(submission.loc[submission['condition'] == 'spinal'].groupby('study_id')['severe'].max())\n",
    "    any_severe_spinal_loss = sklearn.metrics.log_loss(\n",
    "        y_true=any_severe_spinal_labels,\n",
    "        y_pred=any_severe_spinal_predictions,\n",
    "        sample_weight=any_severe_spinal_weights\n",
    "    )\n",
    "    condition_losses.append(any_severe_spinal_loss)\n",
    "    condition_weights.append(any_severe_scalar)\n",
    "    return np.average(condition_losses, weights=condition_weights)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "accd6fa2b74decad",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "results_df = results_df.drop_duplicates(subset=[\"row_id\"]).reset_index(drop=True)\n",
    "test_solution = test_solution.drop_duplicates(subset=[\"row_id\"]).reset_index(drop=True)\n",
    "\n",
    "score(test_solution, results_df, \"row_id\", 1.0)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8e805bf4901d740c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "softmax = nn.Softmax(dim=2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5f599cdd",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "results_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "17a1216e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "\n",
    "    for item_index, item in tqdm(enumerate(testset)):\n",
    "        images, _  = item\n",
    "        output = model(images.unsqueeze(0).to(device))\n",
    "        output = output.reshape((-1, 25, 3))\n",
    "        output = softmax(output)\n",
    "        output = output.detach().cpu().numpy()[0]\n",
    "        study_id = testset.subjects[\"study_id\"].values[item_index]\n",
    "        for index, level in enumerate(output):\n",
    "            row_id = f\"{str(study_id)}_{ALL_CONDITIONS[index // 5]}_{LEVELS[index % 5]}\"\n",
    "            results_df.loc[results_df.row_id == row_id, 'normal_mild'] = level[0]\n",
    "            results_df.loc[results_df.row_id == row_id, 'moderate'] = level[1]\n",
    "            results_df.loc[results_df.row_id == row_id, 'severe'] = level[2]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b86c78e3",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "score(test_solution, results_df, \"row_id\", 1.0)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74c7a95873fb5260",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "\n",
    "    for item_index, item in tqdm(enumerate(testset)):\n",
    "        images, _ = item\n",
    "        output = model(images.unsqueeze(0).to(device))\n",
    "        output = output.reshape((-1, 25, 3))\n",
    "        output = softmax(output * (1 / np.array([1, 2, 4])))\n",
    "        output = output.detach().cpu().numpy()[0]\n",
    "        study_id = testset.subjects[\"study_id\"].values[item_index]\n",
    "        for index, level in enumerate(output):\n",
    "            row_id = f\"{str(study_id)}_{ALL_CONDITIONS[index // 5]}_{LEVELS[index % 5]}\"\n",
    "            results_df.loc[results_df.row_id == row_id, 'normal_mild'] = level[0]\n",
    "            results_df.loc[results_df.row_id == row_id, 'moderate'] = level[1]\n",
    "            results_df.loc[results_df.row_id == row_id, 'severe'] = level[2]\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "39e1ac40",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "score(test_solution, results_df, \"row_id\", 1.0)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b45795bedcec3278",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8e969ebb960f01a4",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 8561470,
     "sourceId": 71549,
     "sourceType": "competition"
    },
    {
     "modelInstanceId": 64271,
     "sourceId": 77199,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelInstanceId": 64905,
     "sourceId": 77213,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 125.382344,
   "end_time": "2024-07-14T02:57:52.077559",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-14T02:55:46.695215",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
